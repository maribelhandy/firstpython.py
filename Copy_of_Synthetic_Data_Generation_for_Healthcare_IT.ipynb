{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maribelhandy/firstpython.py/blob/master/Copy_of_Synthetic_Data_Generation_for_Healthcare_IT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiJMQ9SEWeUm",
        "outputId": "289545a9-c197-465e-d8df-2c127d0a7667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk9WrLqyWmDF",
        "outputId": "54237faa-262e-4f19-8b92-293b990635e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa0lHTdgWtUj",
        "outputId": "95ef3e90-723f-4940-8130-3479afe30486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "id": "M2Gje8pTW3KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "id": "sCMob3EBW9M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fsS-utRDXI5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# dissertation_example.py\n",
        "#\n",
        "# A Python script to demonstrate the core methodology for the dissertation topic:\n",
        "# \"Synthetic Data Generation for Training and Testing IT Systems in Data-Scarce Environments\"\n",
        "#\n",
        "# This script covers:\n",
        "# 1. Simulating a 'real' patient dataset.\n",
        "# 2. Training a Conditional Tabular GAN (CTGAN) model on this data.\n",
        "# 3. Generating a synthetic dataset from the trained model.\n",
        "# 4. Evaluating the synthetic data using two key methods:\n",
        "#    a) Statistical Fidelity Comparison.\n",
        "#    b) Machine Learning Utility (the \"Train-Synthetic-Test-Real\" approach).\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sdv.tabular import CTGAN\n",
        "from sdv.evaluation import evaluate\n",
        "\n",
        "# --- STAGE 1: Simulate a 'Real' Patient Dataset ---\n",
        "# In a real dissertation, you would use a real, sensitive dataset here.\n",
        "##########################################################################\n",
        "# For this example, we generate a realistic-looking but entirely fake dataset\n",
        "#########################################################################\n",
        "# to avoid any privacy concerns.\n",
        "#########################################################################\n",
        "print(\"Step 1: Simulating a 'real' patient dataset...\")\n",
        "\n",
        "# Define the structure and characteristics of our fake data\n",
        "num_samples = 2000\n",
        "data = {\n",
        "    'age': np.random.normal(loc=55, scale=15, size=num_samples).astype(int),\n",
        "    'gender': np.random.choice(['Male', 'Female'], size=num_samples, p=[0.48, 0.52]),\n",
        "    'blood_pressure': np.random.normal(loc=130, scale=20, size=num_samples).astype(int),\n",
        "    'cholesterol': np.random.normal(loc=200, scale=30, size=num_samples).astype(int),\n",
        "    'disease_severity': np.random.choice(['Low', 'Medium', 'High'], size=num_samples, p=[0.6, 0.3, 0.1]),\n",
        "    # The target variable we want to predict\n",
        "    'had_complication': np.zeros(num_samples, dtype=int)\n",
        "}\n",
        "real_data = pd.DataFrame(data)\n",
        "\n",
        "# Create a plausible relationship for the target variable 'had_complication'\n",
        "# Complications are more likely for older patients with high blood pressure/cholesterol\n",
        "real_data.loc[(real_data['age'] > 65) & (real_data['blood_pressure'] > 150), 'had_complication'] = 1\n",
        "real_data.loc[real_data['cholesterol'] > 220, 'had_complication'] = np.random.choice([0, 1], size=len(real_data[real_data['cholesterol'] > 220]), p=[0.7, 0.3])\n",
        "real_data['age'] = real_data['age'].clip(18, 90) # Clip age to be realistic\n",
        "\n",
        "print(\"Real dataset created with {} records.\\n\".format(num_samples))\n",
        "print(\"Real Data Head:\")\n",
        "print(real_data.head())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- STAGE 2: Train the Generative Model (CTGAN) ---\n",
        "# This step addresses the research question: \"Which generative models are most effective?\"\n",
        "# We use CTGAN, a well-regarded model for tabular data.\n",
        "print(\"Step 2: Training the CTGAN model on the real data...\")\n",
        "# Note: In a real project, training can take a significant amount of time.\n",
        "# We'll use a small number of epochs for this demonstration.\n",
        "model = CTGAN(epochs=100, verbose=True) # Increase epochs for better quality\n",
        "model.fit(real_data)\n",
        "print(\"CTGAN model training complete.\\n\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- STAGE 3: Generate Synthetic Data ---\n",
        "# Use the trained model to create a new dataset from scratch.\n",
        "# This new data should capture the statistical properties of the real data\n",
        "# without being a one-to-one copy.\n",
        "print(\"Step 3: Generating synthetic data...\")\n",
        "synthetic_data = model.sample(num_rows=num_samples)\n",
        "print(\"Synthetic dataset generated with {} records.\\n\".format(num_samples))\n",
        "print(\"Synthetic Data Head:\")\n",
        "print(synthetic_data.head())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- STAGE 4: Evaluate the Synthetic Data ---\n",
        "# This is the most critical stage for the dissertation, addressing the questions of\n",
        "# \"High-Fidelity Generation\" and \"Utility & Task Performance\".\n",
        "\n",
        "# --- 4a. Statistical Fidelity Evaluation ---\n",
        "print(\"Step 4a: Evaluating Statistical Fidelity...\")\n",
        "# The SDV library provides a comprehensive evaluation function that compares\n",
        "# the distributions and correlations of columns between the real and synthetic data.\n",
        "# It provides a score from 0 to 1, where 1 is perfect.\n",
        "quality_report = evaluate(synthetic_data, real_data, aggregate=False)\n",
        "print(\"--- Synthetic Data Quality Report ---\")\n",
        "print(quality_report)\n",
        "print(\"\\nInterpreting the report:\")\n",
        "print(\"- Column Shapes: How similar are the distributions of individual columns? (Higher is better)\")\n",
        "print(\"- Column Pair Trends: How well does the synthetic data capture correlations between columns? (Higher is better)\\n\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- 4b. Machine Learning Utility Evaluation (Train-Synthetic-Test-Real) ---\n",
        "print(\"Step 4b: Evaluating Machine Learning Utility (Train-Synthetic-Test-Real)...\")\n",
        "\n",
        "# Define features (X) and the target variable (y)\n",
        "features = ['age', 'gender', 'blood_pressure', 'cholesterol', 'disease_severity']\n",
        "target = 'had_complication'\n",
        "\n",
        "# Pre-process data: One-hot encode categorical variables for the model\n",
        "real_data_processed = pd.get_dummies(real_data, columns=['gender', 'disease_severity'], drop_first=True)\n",
        "synthetic_data_processed = pd.get_dummies(synthetic_data, columns=['gender', 'disease_severity'], drop_first=True)\n",
        "\n",
        "# Align columns to ensure both dataframes have the same features after encoding\n",
        "real_labels = real_data_processed[target]\n",
        "real_features = real_data_processed.drop(columns=[target])\n",
        "\n",
        "synthetic_labels = synthetic_data_processed[target]\n",
        "synthetic_features = synthetic_data_processed.drop(columns=[target])\n",
        "\n",
        "# Ensure columns are in the same order\n",
        "common_cols = list(set(real_features.columns) & set(synthetic_features.columns))\n",
        "real_features = real_features[common_cols]\n",
        "synthetic_features = synthetic_features[common_cols]\n",
        "\n",
        "# Split the REAL data into a training set and a held-out test set\n",
        "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
        "    real_features, real_labels, test_size=0.3, random_state=42, stratify=real_labels\n",
        ")\n",
        "\n",
        "# --- Model 1: Trained and Tested on REAL data (The Benchmark) ---\n",
        "print(\"\\n--- Training Benchmark Model (Real Data) ---\")\n",
        "benchmark_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "benchmark_model.fit(X_train_real, y_train_real)\n",
        "y_pred_real = benchmark_model.predict(X_test_real)\n",
        "\n",
        "benchmark_accuracy = accuracy_score(y_test_real, y_pred_real)\n",
        "benchmark_f1 = f1_score(y_test_real, y_pred_real)\n",
        "\n",
        "print(f\"Benchmark Model Accuracy: {benchmark_accuracy:.4f}\")\n",
        "print(f\"Benchmark Model F1-Score: {benchmark_f1:.4f}\")\n",
        "print(\"Classification Report (Benchmark):\")\n",
        "print(classification_report(y_test_real, y_pred_real))\n",
        "\n",
        "\n",
        "# --- Model 2: Trained on SYNTHETIC data, Tested on REAL data ---\n",
        "print(\"\\n--- Training Synthetic Model ---\")\n",
        "synthetic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "# Train on the full set of synthetic features and labels\n",
        "synthetic_model.fit(synthetic_features, synthetic_labels)\n",
        "\n",
        "# Evaluate on the SAME held-out test set from the REAL data\n",
        "y_pred_synthetic = synthetic_model.predict(X_test_real)\n",
        "\n",
        "synthetic_accuracy = accuracy_score(y_test_real, y_pred_synthetic)\n",
        "synthetic_f1 = f1_score(y_test_real, y_pred_synthetic)\n",
        "\n",
        "print(f\"Synthetic Model Accuracy: {synthetic_accuracy:.4f}\")\n",
        "print(f\"Synthetic Model F1-Score: {synthetic_f1:.4f}\")\n",
        "print(\"Classification Report (Synthetic):\")\n",
        "print(classification_report(y_test_real, y_pred_synthetic))\n",
        "\n",
        "\n",
        "# --- Final Comparison ---\n",
        "print(\"\\n--- Dissertation Experiment Conclusion ---\")\n",
        "print(f\"Performance of Benchmark Model (trained on real data): {benchmark_f1:.4f} F1-Score\")\n",
        "print(f\"Performance of Synthetic Model (trained on synthetic data): {synthetic_f1:.4f} F1-Score\")\n",
        "\n",
        "performance_diff = ((benchmark_f1 - synthetic_f1) / benchmark_f1) * 100\n",
        "print(f\"\\nThe synthetic model achieved performance within {performance_diff:.2f}% of the benchmark model.\")\n",
        "print(\"This result indicates that the synthetic data has high machine learning utility.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Yd-PF_wyVv1y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ecf38e0"
      },
      "source": [
        "!pip install sdv --upgrade --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}